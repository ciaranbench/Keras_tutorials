{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9f648b",
   "metadata": {},
   "source": [
    "# Keras tutorial\n",
    "## Here, we use the model subclassing API to i) conjoin two pretrained models, ii) freeze the parameters of the second model, and then iii) the train the lower-level, first model by backpropagating through the second. \n",
    "## This is a toy example to show how this can be implented in keras, as opposed to learning some useful task. \n",
    "### We also add the capability to use custom loss functions to pretrain each model, and the combined model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6595ef41",
   "metadata": {},
   "source": [
    "### Specifically, we partially train an autoencoder, and seperately partially train a classifier. We then conjoin the two models together (autoencoder -> classifier), freezing the weights of the classifer. The weights of the autoencoder are then updated to prepare inputs in a way that maximises classification accuracy when processed by the partially trained classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235168f",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef84a3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tk\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf. __version__) \n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca4efa",
   "metadata": {},
   "source": [
    "### Load in MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfef2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_train_1 = x_train[1:200,:,:]\n",
    "x_train_2 = x_train[200:1200,:,:]\n",
    "x_train_combined = np.array(x_train[1200:2200,:,:])\n",
    "\n",
    "x_val_1 = x_train[2200:2400,:,:]\n",
    "x_val_2 = x_train[2400:2500,:,:]\n",
    "x_val_combined = np.array(x_train[2500:2600,:,:])\n",
    "\n",
    "x_test_1 = x_train[2600:2700,:,:]\n",
    "x_test_2 =   x_train[2700:2800,:,:]\n",
    "x_test_combined = np.array(x_train[2800:2900,:,:])\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "y_train_1 = y_train[1:200]\n",
    "y_train_2 = y_train[200:1200]\n",
    "y_train_combined = np.array(y_train[1200:2200])\n",
    "\n",
    "y_val_1 = y_train[2200:2400]\n",
    "y_val_2 = y_train[2400:2500]\n",
    "y_val_combined = np.array(y_train[2500:2600])\n",
    "\n",
    "y_test_1 = y_train[2600:2700]\n",
    "y_test_2 = y_train[2700:2800]\n",
    "y_test_combined = np.array(y_train[2800:2900])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28b20f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2161b05ea00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# data is your array\n",
    "\n",
    "array = np.squeeze(x_train_2[0,:,:])\n",
    "print(np.squeeze(y_train_2[0,:]))\n",
    "\n",
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cff0e8",
   "metadata": {},
   "source": [
    "### Define the graph\n",
    "net_1 is a convolutional autoencoder.  \n",
    "net_2 is a classifier.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900d238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "net_input_1 = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(net_input_1)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "#x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Conv2D(1, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(20)(x)\n",
    "x = layers.Dense(49)(x)\n",
    "x = layers.Reshape((7,7,1))(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.UpSampling2D()(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.UpSampling2D()(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "\n",
    "net_output_1 = layers.Conv2D(1, 3, activation=\"relu\",padding=\"SAME\", name=\"net_1_out\")(x)\n",
    "\n",
    "net_input_2 = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "\n",
    "\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\",padding=\"SAME\", name=\"model_2_lay_1\")(net_input_2)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Conv2D(1, 3, activation=\"relu\",padding=\"SAME\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "net_output_2= layers.Dense(num_classes,activation=\"softmax\")(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc9a27",
   "metadata": {},
   "source": [
    "### Set hyperparameters and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bf0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "EPOCHS = 30\n",
    "NET_1_WEIGHTS = 'net_1_30.hd5'\n",
    "NET_2_WEIGHTS = 'net_2_20.hd5' \n",
    "\n",
    "def loss_1(y_true, y_pred):\n",
    "        squared_difference = tf.square(y_true - y_pred)\n",
    "        return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n",
    "    \n",
    "def loss_2(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n",
    "    \n",
    "def loss_3(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2b0d8",
   "metadata": {},
   "source": [
    "### Construct models\n",
    "The combined_model is net_1 and net_2 chained together. \n",
    "The workflow is as follows, and is defiend in the fit function:  \n",
    "i) Check if weights exist for net_1 and net_2. \n",
    "ii) If so, load them in. Otherwise, pretrain each network using their respective pretrain functions. \n",
    "iii) Conjoin both models, and freeze the weights of net_1.\n",
    "iv) Train the combined model using the combined model training function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45cd32c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use self when referring to something defined within the class.\n",
    "# MyModel inherets object class - in python 3, there probably isn't a need to do this, but we keep it to illustrate potential functionality.\n",
    "\n",
    "class MyModel(object):\n",
    "    # initialise instance attributes in __init_ - these are manipulated by the functions in the class.\n",
    "    # Keras model takes variable input_shape as an input, so we include this as an input. \n",
    "    def __init__(self,input_shape):\n",
    "        # super below runs the __init__ of parent class (in this case, object).\n",
    "        # we don't really need this, but it's kept to illustrate potential functionality.\n",
    "        super(MyModel,self).__init__()\n",
    "        # input_shape variable\n",
    "        self.input_shape = input_shape\n",
    "        # net_1 is the autoencoder\n",
    "        self.net_1 = keras.Model(net_input_1, net_output_1, name=\"net_1\")\n",
    "        # net_2 is a CNN classifier appended to the pretrained net_1\n",
    "        self.net_2 = keras.Model(net_input_2, net_output_2, name=\"net_2\")\n",
    "        net_2_out = self.net_2(self.net_1.output)\n",
    "        # the combined network is the pretrained net_1 and net_2 chained together\n",
    "        self.combined_net = keras.Model(self.net_1.input, net_2_out, name=\"combined_net\")\n",
    "        \n",
    "    # we define a function that pretrains net_1, and saves the weights\n",
    "    def pretrain_net_1(self, x, x_val, batch_size=BATCH_SIZE, epochs=100, optimizer='adam', save_dir='./'):\n",
    "        print('...Pretraining net_1...')\n",
    "        class CustomSaver(keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs={}):\n",
    "                # we use self.model because we are inhereting the keras.callbacks.Callback class which uses the model attribute\n",
    "                self.model.save(\"net_1_{}.hd5\".format(epoch))  \n",
    "        self.net_1.compile(optimizer=optimizer, loss=loss_1)\n",
    "        #Log autoencoder module training progress\n",
    "        from keras.callbacks import CSVLogger\n",
    "        csv_logger = CSVLogger('pretrain_log_net_1.csv')\n",
    "        saver = CustomSaver()\n",
    "\n",
    "        # begin training\n",
    "        self.net_1.fit(x, x, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[csv_logger,saver],validation_data=(x_val, x_val))\n",
    "        self.net_1.save(save_dir + '/pretrain_net_1_model')\n",
    "        print('Pretrained weights are saved to %s/pretrain_net_1_model' % save_dir)\n",
    "                \n",
    "    # we also define a function that pretrains net_2, and saves the weights\n",
    "    def pretrain_net_2(self, x, y, x_val, y_val, batch_size=BATCH_SIZE, epochs=100, optimizer='adam', save_dir='./'):\n",
    "        print('...Pretraining net_2...')\n",
    "        class CustomSaver(keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs={}):\n",
    "                # we use self.model because we are inhereting the keras.callbacks.Callback class which uses the model attribute\n",
    "                self.model.save(\"net_2_{}.hd5\".format(epoch))  \n",
    "        self.net_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        #Log autoencoder module training progress\n",
    "        from keras.callbacks import CSVLogger\n",
    "        csv_logger = CSVLogger('pretrain_log_net_2.csv')\n",
    "        saver = CustomSaver()\n",
    "\n",
    "        # begin training\n",
    "        self.net_2.fit(x, y, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[csv_logger,saver],validation_data=(x_val, y_val))\n",
    "        self.net_2.save(save_dir + '/pretrain_net_2_model')\n",
    "        print('Pretrained weights are saved to %s/pretrain_net_2_model' % save_dir)\n",
    "    \n",
    "    # this function trains the combined network                    \n",
    "    def train_combined_net(self, x, y, x_val,y_val, batch_size=BATCH_SIZE, epochs=EPOCHS, optimizer='adam', save_dir='./'):\n",
    "        print('...Training combined_net...')\n",
    "        class CustomSaver(keras.callbacks.Callback):\n",
    "            def on_epoch_end(self, epoch, logs={}):\n",
    "                # we use self.model because we are inhereting the keras.callbacks.Callback class which uses the model attribute\n",
    "                self.model.save(\"combined_net_{}.hd5\".format(epoch))\n",
    "        train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "        val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "        self.combined_net.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
    "        #Log autoencoder module training progress\n",
    "        from keras.callbacks import CSVLogger\n",
    "        csv_logger = CSVLogger('pretrain_log_combined.csv')\n",
    "        saver = CustomSaver()\n",
    "        # begin training\n",
    "        #self.combined_net.fit(x, y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[csv_logger,saver],validation_data=(x_val, y_val))\n",
    "        \n",
    "        #####\n",
    "        import time\n",
    "        epochs = 30\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Iterate over the batches of the dataset.\n",
    "            for batch_index in range((np.floor(x_train_combined.shape[0])/BATCH_SIZE).astype(int)):\n",
    "                x_batch_train = x[batch_index * BATCH_SIZE:(batch_index + 1) * batch_size,:,:]\n",
    "                y_batch_train = y[batch_index * BATCH_SIZE:(batch_index + 1) * batch_size]\n",
    "                \n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = self.combined_net(x_batch_train, training=True)\n",
    "                    loss_value = loss_3(y_batch_train, logits)\n",
    "                grads = tape.gradient(loss_value, self.combined_net.trainable_weights)\n",
    "                optimizer = keras.optimizers.Adam()\n",
    "                optimizer.apply_gradients(zip(grads, self.combined_net.trainable_weights))\n",
    "                y_batch_train = np.expand_dims(y_batch_train,axis=1)\n",
    "                # Update training metric.\n",
    "                #print(y_batch_train)\n",
    "                #print(np.shape(logits))\n",
    "                train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "            # Display metrics at the end of each epoch.\n",
    "            train_acc = train_acc_metric.result()\n",
    "            print(\"Training loss over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "            # Reset training metrics at the end of each epoch\n",
    "            train_acc_metric.reset_states()\n",
    "            \n",
    "            combined_net_validation_outputs = self.combined_net(x_val)\n",
    "            val_acc_metric.update_state(y_val, combined_net_validation_outputs)\n",
    "            val_acc = val_acc_metric.result()\n",
    "            print(\"Validation loss over epoch: %.4f\" % (float(val_acc),))\n",
    "            val_acc_metric.reset_states()\n",
    "\n",
    "            \n",
    "        #####\n",
    "        self.combined_net.save(save_dir + '/train_combined_net_model')\n",
    "        print('combined model weights are saved to %s/pretrain_combined_net_model' % save_dir)\n",
    "\n",
    "        \n",
    "    # in fit, we excute the workflow described in the section's header\n",
    "    def fit(self, x_train_1, y_train_1, x_train_2, y_train_2, x_train_combined, y_train_combined, x_val_1, y_val_1, x_val_2, y_val_2, x_val_combined,y_val_combined, batch_size=BATCH_SIZE, net_1_weights=None,net_2_weights=None, save_dir='./'):\n",
    "        if net_1_weights is None:\n",
    "            print('...pretraining net_1:')\n",
    "            self.pretrain_net_1(x=x_train_1,x_val=x_val_1, batch_size=BATCH_SIZE)\n",
    "            \n",
    "        elif net_1_weights is not None:\n",
    "            print('LOADING net_1 WEIGHTS')\n",
    "            self.net_1.load_weights(net_1_weights)\n",
    "            print('net_1 weights loaded successfully.')\n",
    "            \n",
    "        if net_2_weights is None:\n",
    "            print('...pretraining net_2:')\n",
    "            self.pretrain_net_2(x_train_2, y_train_2,x_val=x_val_2, y_val=y_val_2, batch_size= BATCH_SIZE)\n",
    "            \n",
    "        elif net_2_weights is not None:\n",
    "            print('LOADING net_2 WEIGHTS')\n",
    "            self.net_2.load_weights(net_2_weights)\n",
    "            print('net_2 weights loaded successfully.')\n",
    "            \n",
    "        self.net_2.trainable = False\n",
    "        self.train_combined_net(x_train_combined, y_train_combined, x_val_combined, y_val_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3618fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"combined_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 7, 7, 16)          2320      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 7, 7, 16)          2320      \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 7, 7, 1)           145       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 49)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                1000      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 49)                1029      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 1)           0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 16)          160       \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 16)          2320      \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 14, 14, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 28, 28, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 16)        2320      \n",
      "                                                                 \n",
      " net_1_out (Conv2D)          (None, 28, 28, 1)         145       \n",
      "                                                                 \n",
      " net_2 (Functional)          (None, 10)                38117     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,636\n",
      "Trainable params: 61,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "LOADING net_1 WEIGHTS\n",
      "net_1 weights loaded successfully.\n",
      "LOADING net_2 WEIGHTS\n",
      "net_2 weights loaded successfully.\n",
      "...Training combined_net...\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss over epoch: 0.6300\n",
      "Validation loss over epoch: 0.6700\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss over epoch: 0.7590\n",
      "Validation loss over epoch: 0.7300\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss over epoch: 0.8140\n",
      "Validation loss over epoch: 0.6700\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss over epoch: 0.8380\n",
      "Validation loss over epoch: 0.7500\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss over epoch: 0.8760\n",
      "Validation loss over epoch: 0.8100\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss over epoch: 0.8520\n",
      "Validation loss over epoch: 0.8600\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss over epoch: 0.8830\n",
      "Validation loss over epoch: 0.8300\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss over epoch: 0.8870\n",
      "Validation loss over epoch: 0.9000\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss over epoch: 0.9010\n",
      "Validation loss over epoch: 0.8500\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss over epoch: 0.8850\n",
      "Validation loss over epoch: 0.8800\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss over epoch: 0.9110\n",
      "Validation loss over epoch: 0.8700\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss over epoch: 0.9120\n",
      "Validation loss over epoch: 0.9300\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss over epoch: 0.9070\n",
      "Validation loss over epoch: 0.9000\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss over epoch: 0.9350\n",
      "Validation loss over epoch: 0.9100\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss over epoch: 0.9340\n",
      "Validation loss over epoch: 0.9100\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss over epoch: 0.9520\n",
      "Validation loss over epoch: 0.9300\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss over epoch: 0.9430\n",
      "Validation loss over epoch: 0.8400\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss over epoch: 0.9290\n",
      "Validation loss over epoch: 0.9400\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss over epoch: 0.9500\n",
      "Validation loss over epoch: 0.8900\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss over epoch: 0.9480\n",
      "Validation loss over epoch: 0.8900\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss over epoch: 0.9570\n",
      "Validation loss over epoch: 0.9300\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss over epoch: 0.9620\n",
      "Validation loss over epoch: 0.9300\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss over epoch: 0.9640\n",
      "Validation loss over epoch: 0.8300\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss over epoch: 0.9600\n",
      "Validation loss over epoch: 0.8900\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss over epoch: 0.9600\n",
      "Validation loss over epoch: 0.9000\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss over epoch: 0.9650\n",
      "Validation loss over epoch: 0.9300\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss over epoch: 0.9620\n",
      "Validation loss over epoch: 0.8900\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss over epoch: 0.9550\n",
      "Validation loss over epoch: 0.9200\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss over epoch: 0.9620\n",
      "Validation loss over epoch: 0.9500\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss over epoch: 0.9690\n",
      "Validation loss over epoch: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .//train_combined_net_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .//train_combined_net_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined model weights are saved to .//pretrain_combined_net_model\n"
     ]
    }
   ],
   "source": [
    "our_model = MyModel(input_shape = (28,28,1))\n",
    "our_model.combined_net.summary()\n",
    "our_model.fit(x_train_1 = x_train_1, y_train_1=y_train_1, x_train_2=x_train_2, y_train_2=y_train_2, x_train_combined=x_train_combined, y_train_combined=y_train_combined, x_val_1=x_val_1, y_val_1=y_val_1,x_val_2=x_val_2, y_val_2=y_val_2, x_val_combined=x_val_combined,y_val_combined=y_val_combined, batch_size=BATCH_SIZE,net_1_weights=NET_1_WEIGHTS, net_2_weights=NET_2_WEIGHTS, save_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd47764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.3865113258361816\n"
     ]
    }
   ],
   "source": [
    "score = our_model.combined_net.evaluate(x_test_combined, y_test_combined, verbose=0)\n",
    "print(\"Test loss:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb1cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
